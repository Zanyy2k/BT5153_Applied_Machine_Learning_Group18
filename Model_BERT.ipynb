{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Model_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "884c0890d9ba4aefa671ad6ab28412d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9fced8acb75f416a9ad12a03c8df4080",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_17c248f252ed4b5087e05bc8ee8b312f",
              "IPY_MODEL_57157f6565ff401499a082ad33f4f4f0"
            ]
          }
        },
        "9fced8acb75f416a9ad12a03c8df4080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17c248f252ed4b5087e05bc8ee8b312f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7becfa13560e40f3af2363a04ac65e80",
            "_dom_classes": [],
            "description": "Epoch: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f85dc8d9e3a64796b8732de2b5a7bc6c"
          }
        },
        "57157f6565ff401499a082ad33f4f4f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f32bf516e69a42359d99fbefecc8abd4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [6:07:41&lt;00:00, 5515.26s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5a7e529c38146d0a6df232f5ecc7cdf"
          }
        },
        "7becfa13560e40f3af2363a04ac65e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f85dc8d9e3a64796b8732de2b5a7bc6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f32bf516e69a42359d99fbefecc8abd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5a7e529c38146d0a6df232f5ecc7cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9673f67935f84aef914587f6cbb93c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_da70e993c0cf439195131223209f4fea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cfa6d16fcdd4bb38ca620c2b6d12f44",
              "IPY_MODEL_bdeda14ee20a4342b856a428afd0bf3b"
            ]
          }
        },
        "da70e993c0cf439195131223209f4fea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cfa6d16fcdd4bb38ca620c2b6d12f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e9e191eede6c4d77ac7d4a90961c9f3f",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 17952,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 17952,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34659a753ed34da085596ecfc3650902"
          }
        },
        "bdeda14ee20a4342b856a428afd0bf3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff356280191645c7992df2eb36b17707",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 17952/17952 [1:28:14&lt;00:00,  3.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe40d4371ff64ca29484d8de0c57c9e2"
          }
        },
        "e9e191eede6c4d77ac7d4a90961c9f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34659a753ed34da085596ecfc3650902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff356280191645c7992df2eb36b17707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe40d4371ff64ca29484d8de0c57c9e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef51a39f2da14f28b8ba9f81c6498d61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b580c768d5c54875a95ab325836e2c12",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9091dc64b9c24364b8fbaac5c95137ba",
              "IPY_MODEL_1da82a8ebd8f4ed29879303956f9291d"
            ]
          }
        },
        "b580c768d5c54875a95ab325836e2c12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9091dc64b9c24364b8fbaac5c95137ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_06b950e55480412c8b56975c70ab852d",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 17952,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 17952,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3d1405b088d461ea52c30786ee18af2"
          }
        },
        "1da82a8ebd8f4ed29879303956f9291d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c5bcc9af196347a6b49f502db83071fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 17952/17952 [4:30:00&lt;00:00,  1.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2dafef43c484a17a21b1a82b9ab756f"
          }
        },
        "06b950e55480412c8b56975c70ab852d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3d1405b088d461ea52c30786ee18af2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5bcc9af196347a6b49f502db83071fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2dafef43c484a17a21b1a82b9ab756f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "540e0fe269f44260a03d4bff28ae1c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c4476aa6b3ee4e028bb89f10ba9eef97",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cbfca39bd22f4e6b95c36ef176a46141",
              "IPY_MODEL_d1ac5ecfe5cf4920b7b827dc58eeaf33"
            ]
          }
        },
        "c4476aa6b3ee4e028bb89f10ba9eef97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbfca39bd22f4e6b95c36ef176a46141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da77f1158ddc438888c65b024b61382c",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 17952,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 17952,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9de6dd1235c643d5949813952ac4a56c"
          }
        },
        "d1ac5ecfe5cf4920b7b827dc58eeaf33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5b52c58c985242a7b434f6a5777b6175",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 17952/17952 [1:26:42&lt;00:00,  3.45it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7880eeb4bfec4ae39b0ca2b2c4125536"
          }
        },
        "da77f1158ddc438888c65b024b61382c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9de6dd1235c643d5949813952ac4a56c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b52c58c985242a7b434f6a5777b6175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7880eeb4bfec4ae39b0ca2b2c4125536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "696d052fb7024fefaabbd575164579b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_54e81eff0da44a9dbe8af10689629435",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b8ea50d5178477c94d91c3589877f47",
              "IPY_MODEL_d05f5774d48e41d38492495724a1c166"
            ]
          }
        },
        "54e81eff0da44a9dbe8af10689629435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b8ea50d5178477c94d91c3589877f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8e5f99229941409caa469e864473c754",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 17952,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 17952,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d7ade74ef1d4b559f70282a6d85606e"
          }
        },
        "d05f5774d48e41d38492495724a1c166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_688351303f8a4cdcb047dc895b1f6ad5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 17952/17952 [1:26:57&lt;00:00,  3.44it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e7f010b3e944caa97002f12fa74ce2e"
          }
        },
        "8e5f99229941409caa469e864473c754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d7ade74ef1d4b559f70282a6d85606e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "688351303f8a4cdcb047dc895b1f6ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e7f010b3e944caa97002f12fa74ce2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sZZfptQIju5N",
        "outputId": "c5bd1d16-6ccc-419f-d577-c414cbe93390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KwYaGj9OkfBS",
        "outputId": "7ecf5c20-d3ae-4ba2-b7ca-5e0c218d2d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -q pytorch_pretrained_bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▋                             | 10kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 3.3MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qKhPP26omEpX",
        "outputId": "9c0de1ec-c58d-4a65-9273-64f4eaca64c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!pip3 uninstall apex\n",
        "!git clone https://www.github.com/nvidia/apex"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping apex as it is not installed.\u001b[0m\n",
            "Cloning into 'apex'...\n",
            "warning: redirecting to https://github.com/nvidia/apex.git/\n",
            "remote: Enumerating objects: 332, done.\u001b[K\n",
            "remote: Counting objects: 100% (332/332), done.\u001b[K\n",
            "remote: Compressing objects: 100% (207/207), done.\u001b[K\n",
            "remote: Total 6534 (delta 246), reused 191 (delta 125), pack-reused 6202\u001b[K\n",
            "Receiving objects: 100% (6534/6534), 13.72 MiB | 10.39 MiB/s, done.\n",
            "Resolving deltas: 100% (4317/4317), done.\n",
            "Checking out files: 100% (254/254), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sfgX4lkSmcsl",
        "outputId": "1f3e785c-cead-4c0e-d5e2-cc40686de97d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "os.chdir('./apex')\n",
        "#!python3 setup.py install --cuda_ext\n",
        "!pip install --quiet --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3pKbRNUfj7vi",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert.tokenization import BertTokenizer, WordpieceTokenizer\n",
        "from pytorch_pretrained_bert.modeling import BertForPreTraining, BertPreTrainedModel, BertModel, BertConfig, BertForMaskedLM, BertForSequenceClassification\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import re\n",
        "from torch import Tensor\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from fastai.text import Tokenizer, Vocab\n",
        "import pandas as pd\n",
        "import collections\n",
        "import os\n",
        "import pdb\n",
        "from tqdm import tqdm, trange\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import apex\n",
        "from sklearn.model_selection import train_test_split\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from pytorch_pretrained_bert.optimization import BertAdam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pj1yd5Oej71a",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drCkYYTZm8Sj",
        "colab_type": "code",
        "outputId": "0a9d016d-41bb-4163-8e1e-e093dab6a590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip -q install ipywidgets\n",
        "!jupyter nbextension enable --py widgetsnbextension"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enabling notebook extension jupyter-js-widgets/extension...\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0Iel70ZGmsrR",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/toxic_comments/data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GSePYJFcmput",
        "colab": {}
      },
      "source": [
        "DATA_PATH=Path('.')\n",
        "DATA_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "PATH=Path('./tmp')\n",
        "PATH.mkdir(exist_ok=True)\n",
        "\n",
        "CLAS_DATA_PATH=PATH/'class'\n",
        "CLAS_DATA_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "model_state_dict = None\n",
        "\n",
        "# BERT_PRETRAINED_PATH = Path('../trained_model/')\n",
        "BERT_PRETRAINED_PATH = Path('./pretrained/uncased_L-12_H-768_A-12/')\n",
        "\n",
        "PYTORCH_PRETRAINED_BERT_CACHE = BERT_PRETRAINED_PATH/'cache/'\n",
        "PYTORCH_PRETRAINED_BERT_CACHE.mkdir(exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6qUTUmaL3a_F",
        "colab": {}
      },
      "source": [
        "# Model Parameters\n",
        "args = {\n",
        "    \"train_size\": -1,\n",
        "    \"val_size\": -1,\n",
        "    \"full_data_dir\": DATA_PATH,\n",
        "    \"data_dir\": PATH,\n",
        "    \"task_name\": \"toxic_multilabel\",\n",
        "    \"no_cuda\": False,\n",
        "    \"bert_model\": BERT_PRETRAINED_PATH,\n",
        "    \"output_dir\": CLAS_DATA_PATH/'output',\n",
        "    \"max_seq_length\": 256,\n",
        "    #\"max_seq_length\": 516,\n",
        "    \"do_train\": True,\n",
        "    \"do_eval\": True,\n",
        "    \"do_lower_case\": True,\n",
        "    \"train_batch_size\": 8,\n",
        "    \"eval_batch_size\": 8,\n",
        "    \"learning_rate\": 3e-5,\n",
        "    \"num_train_epochs\": 4.0,\n",
        "    \"warmup_proportion\": 0.1,\n",
        "    \"no_cuda\": False,\n",
        "    \"local_rank\": -1,\n",
        "    \"seed\": 42,\n",
        "    \"gradient_accumulation_steps\": 1,\n",
        "    \"optimize_on_cpu\": False,\n",
        "    \"fp16\": False,\n",
        "    \"loss_scale\": 128\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tTYTdcfD3bBu",
        "colab": {}
      },
      "source": [
        "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
        "    \"\"\"BERT model for classification.\n",
        "    This module is composed of the BERT model with a linear layer on top of\n",
        "    the pooled output.\n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels=2):\n",
        "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = BCEWithLogitsLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
        "            return loss\n",
        "        else:\n",
        "            return logits\n",
        "        \n",
        "    def freeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "    \n",
        "    def unfreeze_bert_encoder(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kyhXCk9Z3bE2",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, labels=None):\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_ids = label_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nis4rbzq8tTd",
        "colab": {}
      },
      "source": [
        "class DataProcessor(object):\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError() \n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f7kVvKQq8uMf",
        "colab": {}
      },
      "source": [
        "class MultiLabelTextProcessor(DataProcessor):\n",
        "    \n",
        "    def __init__(self, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.labels = None\n",
        "    \n",
        "    \n",
        "    def get_train_examples(self, data_dir, size=-1):\n",
        "        filename = 'train_train_final_processed.csv'\n",
        "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, filename)))\n",
        "        if size == -1:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "            data_df['comment_text'] = data_df['comment_text'].apply(lambda x: x if isinstance(x, str) else \"something\")\n",
        "            return self._create_examples(data_df, \"train\")\n",
        "        else:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "            data_df['comment_text'] = data_df['comment_text'].apply(lambda x: x if isinstance(x, str) else \"something\")\n",
        "            return self._create_examples(data_df.sample(size), \"train\")\n",
        "        \n",
        "    def get_dev_examples(self, data_dir, size=-1):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        filename = 'train_val_final_processed.csv'\n",
        "        if size == -1:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "            data_df['comment_text'] = data_df['comment_text'].apply(lambda x: x if isinstance(x, str) else \"something\")\n",
        "            return self._create_examples(data_df, \"dev\")\n",
        "        else:\n",
        "            data_df = pd.read_csv(os.path.join(data_dir, filename))\n",
        "            data_df['comment_text'] = data_df['comment_text'].apply(lambda x: x if isinstance(x, str) else \"something\")\n",
        "            return self._create_examples(data_df.sample(size), \"dev\")\n",
        "    \n",
        "    def get_test_examples(self, data_dir, data_file_name, size=-1):\n",
        "        data_df = pd.read_csv(os.path.join(data_dir, data_file_name))\n",
        "        data_df['comment_text'] = data_df['comment_text'].apply(lambda x: x if isinstance(x, str) else \"something\")\n",
        "        if size == -1:\n",
        "            return self._create_examples(data_df, \"test\")\n",
        "        else:\n",
        "            return self._create_examples(data_df.sample(size), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        self.labels = ['toxic', 'severe_toxic',\t'obscene', 'threat',\t'insult',\t'identity_hate']\n",
        "        if self.labels == None:\n",
        "          self.labels = ['toxic', 'severe_toxic',\t'obscene', 'threat',\t'insult',\t'identity_hate']\n",
        "        return self.labels\n",
        "\n",
        "    def _create_examples(self, df, set_type, labels_available=True):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, row) in enumerate(df.values):\n",
        "            guid = row[0]\n",
        "            text_a = row[1]\n",
        "            if labels_available:\n",
        "                labels = row[2:]\n",
        "            else:\n",
        "                labels = []\n",
        "            examples.append(\n",
        "                InputExample(guid=guid, text_a=text_a, labels=labels))\n",
        "        return examples\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pOyfOX5-81eq",
        "colab": {}
      },
      "source": [
        "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
        "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "    label_map = {label : i for i, label in enumerate(label_list)}\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        tokens_a = tokenizer.tokenize(example.text_a)\n",
        "\n",
        "        tokens_b = None\n",
        "        if example.text_b:\n",
        "            tokens_b = tokenizer.tokenize(example.text_b)\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "        else:\n",
        "            # Account for [CLS] and [SEP] with \"- 2\"\n",
        "            if len(tokens_a) > max_seq_length - 2:\n",
        "                tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "\n",
        "        tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
        "        segment_ids = [0] * len(tokens)\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens += tokens_b + [\"[SEP]\"]\n",
        "            segment_ids += [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding = [0] * (max_seq_length - len(input_ids))\n",
        "        input_ids += padding\n",
        "        input_mask += padding\n",
        "        segment_ids += padding\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        \n",
        "        labels_ids = []\n",
        "        for label in example.labels:\n",
        "            labels_ids.append(float(label))\n",
        "\n",
        "        if ex_index < 0:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\" % (example.guid))\n",
        "            logger.info(\"tokens: %s\" % \" \".join(\n",
        "                    [str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "            logger.info(\n",
        "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label: %s (id = %s)\" % (example.labels, labels_ids))\n",
        "\n",
        "        features.append(\n",
        "                InputFeatures(input_ids=input_ids,\n",
        "                              input_mask=input_mask,\n",
        "                              segment_ids=segment_ids,\n",
        "                              label_ids=labels_ids))\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bI49vRsk84LG",
        "colab": {}
      },
      "source": [
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j4eWgGXH86iu",
        "colab": {}
      },
      "source": [
        "def accuracy(out, labels):\n",
        "    outputs = np.argmax(out, axis=1)\n",
        "    return np.sum(outputs == labels)\n",
        "\n",
        "def accuracy_thresh(y_pred:Tensor, y_true:Tensor, thresh:float=0.5, sigmoid:bool=True):\n",
        "    \"Compute accuracy when `y_pred` and `y_true` are the same size.\"\n",
        "    if sigmoid: y_pred = y_pred.sigmoid()\n",
        "    return np.mean(((y_pred>thresh)==y_true.byte()).float().cpu().numpy(), axis=1).sum()\n",
        "\n",
        "\n",
        "def fbeta(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True):\n",
        "    \"Computes the f_beta between `preds` and `targets`\"\n",
        "    beta2 = beta ** 2\n",
        "    if sigmoid: y_pred = y_pred.sigmoid()\n",
        "    y_pred = (y_pred>thresh).float()\n",
        "    y_true = y_true.float()\n",
        "    TP = (y_pred*y_true).sum(dim=1)\n",
        "    prec = TP/(y_pred.sum(dim=1)+eps)\n",
        "    rec = TP/(y_true.sum(dim=1)+eps)\n",
        "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
        "    return res.mean().item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DnB34D2789Vz",
        "colab": {}
      },
      "source": [
        "def warmup_linear(x, warmup=0.002):\n",
        "    if x < warmup:\n",
        "        return x/warmup\n",
        "    return 1.0 - x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kOrc1dwy8_7j",
        "outputId": "db8be164-878f-4594-91d3-fec66787067e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "processors = {\n",
        "    \"toxic_multilabel\": MultiLabelTextProcessor\n",
        "}\n",
        "\n",
        "# Setup GPU parameters\n",
        "\n",
        "if args[\"local_rank\"] == -1 or args[\"no_cuda\"]:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args[\"no_cuda\"] else \"cpu\")\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "#     n_gpu = 1\n",
        "else:\n",
        "    torch.cuda.set_device(args['local_rank'])\n",
        "    device = torch.device(\"cuda\", args['local_rank'])\n",
        "    n_gpu = 1\n",
        "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
        "    torch.distributed.init_process_group(backend='nccl')\n",
        "logger.info(\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\".format(\n",
        "        device, n_gpu, bool(args['local_rank'] != -1), args['fp16']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/21/2020 17:45:23 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bJBCYdM_9C65",
        "colab": {}
      },
      "source": [
        "args['train_batch_size'] = int(args['train_batch_size'] / args['gradient_accumulation_steps'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rDgOAS3s9E3v",
        "colab": {}
      },
      "source": [
        "random.seed(args['seed'])\n",
        "np.random.seed(args['seed'])\n",
        "torch.manual_seed(args['seed'])\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed_all(args['seed'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "71HxWUSH9G6z",
        "colab": {}
      },
      "source": [
        "task_name = args['task_name'].lower()\n",
        "if task_name not in processors:\n",
        "    raise ValueError(\"Task not found: %s\" % (task_name))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YLLCshZK9KOn",
        "colab": {}
      },
      "source": [
        "processor = processors[task_name](args['data_dir'])\n",
        "label_list = processor.get_labels()\n",
        "num_labels = len(label_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xROTOl-0-1ez",
        "outputId": "a989221d-a3ae-4fb3-dd4f-b44cdf31e69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(args['bert_model'], do_lower_case=args['do_lower_case'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/21/2020 17:45:29 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file pretrained/uncased_L-12_H-768_A-12/vocab.txt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Myg_qBsB-1hf",
        "outputId": "fb862acb-25ef-4bf9-a9ee-72ee1f17a41b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_examples = None\n",
        "num_train_steps = None\n",
        "if args['do_train']:\n",
        "    train_examples = processor.get_train_examples(args['full_data_dir'], size=args['train_size'])\n",
        "    num_train_steps = int(\n",
        "        len(train_examples) / args['train_batch_size'] / args['gradient_accumulation_steps'] * args['num_train_epochs'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/21/2020 17:45:30 - INFO - __main__ -   LOOKING AT ./train_train_final_processed.csv\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_tEepLvg-1kU",
        "outputId": "2169c198-a592-4fa1-8db2-e4f4e9379827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# Prepare model\n",
        "def get_model():\n",
        "    if model_state_dict:\n",
        "        model = BertForMultiLabelSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels, state_dict=model_state_dict)\n",
        "    else:\n",
        "        model = BertForMultiLabelSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels)\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "\n",
        "if args['fp16']:\n",
        "    model.half()\n",
        "model.to(device)\n",
        "if args['local_rank'] != -1:\n",
        "    try:\n",
        "        from apex.parallel import DistributedDataParallel as DDP\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
        "\n",
        "    model = DDP(model)\n",
        "elif n_gpu > 1:\n",
        "    model = torch.nn.DataParallel(model)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/21/2020 17:46:05 - INFO - pytorch_pretrained_bert.modeling -   loading archive file pretrained/uncased_L-12_H-768_A-12 from cache at pretrained/uncased_L-12_H-768_A-12\n",
            "04/21/2020 17:46:05 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/21/2020 17:46:08 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForMultiLabelSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "04/21/2020 17:46:08 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IcKvf6u3-1mp",
        "colab": {}
      },
      "source": [
        "from torch.optim.lr_scheduler import _LRScheduler, Optimizer\n",
        "\n",
        "class CyclicLR(object):\n",
        "   \n",
        "    def __init__(self, optimizer, base_lr=1e-3, max_lr=6e-3,\n",
        "                 step_size=2000, mode='triangular', gamma=1.,\n",
        "                 scale_fn=None, scale_mode='cycle', last_batch_iteration=-1):\n",
        "\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        if isinstance(base_lr, list) or isinstance(base_lr, tuple):\n",
        "            if len(base_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} base_lr, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(base_lr)))\n",
        "            self.base_lrs = list(base_lr)\n",
        "        else:\n",
        "            self.base_lrs = [base_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        if isinstance(max_lr, list) or isinstance(max_lr, tuple):\n",
        "            if len(max_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} max_lr, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(max_lr)))\n",
        "            self.max_lrs = list(max_lr)\n",
        "        else:\n",
        "            self.max_lrs = [max_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        self.step_size = step_size\n",
        "\n",
        "        if mode not in ['triangular', 'triangular2', 'exp_range'] \\\n",
        "                and scale_fn is None:\n",
        "            raise ValueError('mode is invalid and scale_fn is None')\n",
        "\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "\n",
        "        if scale_fn is None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = self._triangular_scale_fn\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = self._triangular2_scale_fn\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = self._exp_range_scale_fn\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "\n",
        "        self.batch_step(last_batch_iteration + 1)\n",
        "        self.last_batch_iteration = last_batch_iteration\n",
        "\n",
        "    def batch_step(self, batch_iteration=None):\n",
        "        if batch_iteration is None:\n",
        "            batch_iteration = self.last_batch_iteration + 1\n",
        "        self.last_batch_iteration = batch_iteration\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "    def _triangular_scale_fn(self, x):\n",
        "        return 1.\n",
        "\n",
        "    def _triangular2_scale_fn(self, x):\n",
        "        return 1 / (2. ** (x - 1))\n",
        "\n",
        "    def _exp_range_scale_fn(self, x):\n",
        "        return self.gamma**(x)\n",
        "\n",
        "    def get_lr(self):\n",
        "        step_size = float(self.step_size)\n",
        "        cycle = np.floor(1 + self.last_batch_iteration / (2 * step_size))\n",
        "        x = np.abs(self.last_batch_iteration / step_size - 2 * cycle + 1)\n",
        "\n",
        "        lrs = []\n",
        "        param_lrs = zip(self.optimizer.param_groups, self.base_lrs, self.max_lrs)\n",
        "        for param_group, base_lr, max_lr in param_lrs:\n",
        "            base_height = (max_lr - base_lr) * np.maximum(0, (1 - x))\n",
        "            if self.scale_mode == 'cycle':\n",
        "                lr = base_lr + base_height * self.scale_fn(cycle)\n",
        "            else:\n",
        "                lr = base_lr + base_height * self.scale_fn(self.last_batch_iteration)\n",
        "            lrs.append(lr)\n",
        "        return lrs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RSTBCGgdcv3w",
        "colab": {}
      },
      "source": [
        "# Prepare optimizer\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "t_total = num_train_steps\n",
        "if args['local_rank'] != -1:\n",
        "    t_total = t_total // torch.distributed.get_world_size()\n",
        "if args['fp16']:\n",
        "    try:\n",
        "        from apex.optimizers import FP16_Optimizer\n",
        "        from apex.optimizers import FusedAdam\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\")\n",
        "\n",
        "    optimizer = FusedAdam(optimizer_grouped_parameters,\n",
        "                          lr=args['learning_rate'],\n",
        "                          bias_correction=False,\n",
        "                          max_grad_norm=1.0)\n",
        "    if args['loss_scale'] == 0:\n",
        "        optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
        "    else:\n",
        "        optimizer = FP16_Optimizer(optimizer, static_loss_scale=args['loss_scale'])\n",
        "\n",
        "else:\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                         lr=args['learning_rate'],\n",
        "                         warmup=args['warmup_proportion'],\n",
        "                         t_total=t_total)\n",
        "\n",
        "scheduler = CyclicLR(optimizer, base_lr=2e-5, max_lr=5e-5, step_size=2500, last_batch_iteration=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5XGhY72ac0B6",
        "colab": {}
      },
      "source": [
        "# Eval Fn\n",
        "eval_examples = processor.get_dev_examples(args['data_dir'], size=args['val_size'])\n",
        "def eval():\n",
        "    args['output_dir'].mkdir(exist_ok=True)\n",
        "\n",
        "    \n",
        "    eval_features = convert_examples_to_features(\n",
        "        eval_examples, label_list, args['max_seq_length'], tokenizer)\n",
        "    logger.info(\"***** Running evaluation *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
        "    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n",
        "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
        "    all_label_ids = torch.tensor([f.label_ids for f in eval_features], dtype=torch.float)\n",
        "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "    # Run prediction for full data\n",
        "    eval_sampler = SequentialSampler(eval_data)\n",
        "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n",
        "    \n",
        "    all_logits = None\n",
        "    all_labels = None\n",
        "    \n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    for input_ids, input_mask, segment_ids, label_ids in eval_dataloader:\n",
        "        input_ids = input_ids.to(device)\n",
        "        input_mask = input_mask.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "        label_ids = label_ids.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            tmp_eval_loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "            logits = model(input_ids, segment_ids, input_mask)\n",
        "\n",
        "        tmp_eval_accuracy = accuracy_thresh(logits, label_ids)\n",
        "        if all_logits is None:\n",
        "            all_logits = logits.detach().cpu().numpy()\n",
        "        else:\n",
        "            all_logits = np.concatenate((all_logits, logits.detach().cpu().numpy()), axis=0)\n",
        "            \n",
        "        if all_labels is None:\n",
        "            all_labels = label_ids.detach().cpu().numpy()\n",
        "        else:    \n",
        "            all_labels = np.concatenate((all_labels, label_ids.detach().cpu().numpy()), axis=0)\n",
        "        \n",
        "\n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        nb_eval_examples += input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
        "    \n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    \n",
        "    for i in range(num_labels):\n",
        "        fpr[i], tpr[i], _ = roc_curve(all_labels[:, i], all_logits[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        \n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(all_labels.ravel(), all_logits.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "    result = {'eval_loss': eval_loss,\n",
        "              'eval_accuracy': eval_accuracy,\n",
        "#               'loss': tr_loss/nb_tr_steps,\n",
        "              'roc_auc': roc_auc  }\n",
        "\n",
        "    output_eval_file = os.path.join(args['output_dir'], \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results *****\")\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "#             writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BgsCjx9Cc0G1",
        "colab": {}
      },
      "source": [
        "train_features = convert_examples_to_features(\n",
        "    train_examples, label_list, args['max_seq_length'], tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jMRYWQ9Lc0Lr",
        "outputId": "cf006747-8edc-493d-a8df-927ea6637d12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "logger.info(\"***** Running training *****\")\n",
        "logger.info(\"  Num examples = %d\", len(train_examples))\n",
        "logger.info(\"  Batch size = %d\", args['train_batch_size'])\n",
        "logger.info(\"  Num steps = %d\", num_train_steps)\n",
        "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
        "all_label_ids = torch.tensor([f.label_ids for f in train_features], dtype=torch.float)\n",
        "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "if args['local_rank'] == -1:\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "else:\n",
        "    train_sampler = DistributedSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args['train_batch_size'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "04/21/2020 17:49:13 - INFO - __main__ -   ***** Running training *****\n",
            "04/21/2020 17:49:13 - INFO - __main__ -     Num examples = 143614\n",
            "04/21/2020 17:49:13 - INFO - __main__ -     Batch size = 8\n",
            "04/21/2020 17:49:13 - INFO - __main__ -     Num steps = 71807\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EbaI8fwbkegz",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Du2HLwpJkhfK",
        "colab": {}
      },
      "source": [
        "def fit(num_epocs=args['num_train_epochs']):\n",
        "    global_step = 0\n",
        "    model.train()\n",
        "    for i_ in tqdm(range(int(num_epocs)), desc=\"Epoch\"):\n",
        "\n",
        "        tr_loss = 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
        "\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, input_mask, segment_ids, label_ids = batch\n",
        "            loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "            if n_gpu > 1:\n",
        "                loss = loss.mean() # mean() to average on multi-gpu.\n",
        "            if args['gradient_accumulation_steps'] > 1:\n",
        "                loss = loss / args['gradient_accumulation_steps']\n",
        "\n",
        "            if args['fp16']:\n",
        "                optimizer.backward(loss)\n",
        "            else:\n",
        "                loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            nb_tr_examples += input_ids.size(0)\n",
        "            nb_tr_steps += 1\n",
        "            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n",
        "                lr_this_step = args['learning_rate'] * warmup_linear(global_step/t_total, args['warmup_proportion'])\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group['lr'] = lr_this_step\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "        model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
        "        output_model_file = os.path.join(PYTORCH_PRETRAINED_BERT_CACHE, \"finetuned_pytorch_model_epoch_\" + str(i_) + \".bin\")\n",
        "        torch.save(model_to_save.state_dict(), output_model_file)\n",
        "        logger.info('Loss after epoc {}'.format(tr_loss / nb_tr_steps))\n",
        "        logger.info('Eval after epoc {}'.format(i_+1))\n",
        "        eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNiMhBNQ9PnU",
        "colab_type": "text"
      },
      "source": [
        "### Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mQfeTtAMkhiR",
        "colab": {}
      },
      "source": [
        "model.unfreeze_bert_encoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P_M0b35wkhk4",
        "outputId": "4e2e96aa-dd25-458e-a6b9-3037d3cf90af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996,
          "referenced_widgets": [
            "884c0890d9ba4aefa671ad6ab28412d6",
            "9fced8acb75f416a9ad12a03c8df4080",
            "17c248f252ed4b5087e05bc8ee8b312f",
            "57157f6565ff401499a082ad33f4f4f0",
            "7becfa13560e40f3af2363a04ac65e80",
            "f85dc8d9e3a64796b8732de2b5a7bc6c",
            "f32bf516e69a42359d99fbefecc8abd4",
            "f5a7e529c38146d0a6df232f5ecc7cdf",
            "9673f67935f84aef914587f6cbb93c15",
            "da70e993c0cf439195131223209f4fea",
            "5cfa6d16fcdd4bb38ca620c2b6d12f44",
            "bdeda14ee20a4342b856a428afd0bf3b",
            "e9e191eede6c4d77ac7d4a90961c9f3f",
            "34659a753ed34da085596ecfc3650902",
            "ff356280191645c7992df2eb36b17707",
            "fe40d4371ff64ca29484d8de0c57c9e2",
            "ef51a39f2da14f28b8ba9f81c6498d61",
            "b580c768d5c54875a95ab325836e2c12",
            "9091dc64b9c24364b8fbaac5c95137ba",
            "1da82a8ebd8f4ed29879303956f9291d",
            "06b950e55480412c8b56975c70ab852d",
            "b3d1405b088d461ea52c30786ee18af2",
            "c5bcc9af196347a6b49f502db83071fd",
            "d2dafef43c484a17a21b1a82b9ab756f",
            "540e0fe269f44260a03d4bff28ae1c82",
            "c4476aa6b3ee4e028bb89f10ba9eef97",
            "cbfca39bd22f4e6b95c36ef176a46141",
            "d1ac5ecfe5cf4920b7b827dc58eeaf33",
            "da77f1158ddc438888c65b024b61382c",
            "9de6dd1235c643d5949813952ac4a56c",
            "5b52c58c985242a7b434f6a5777b6175",
            "7880eeb4bfec4ae39b0ca2b2c4125536",
            "696d052fb7024fefaabbd575164579b2",
            "54e81eff0da44a9dbe8af10689629435",
            "4b8ea50d5178477c94d91c3589877f47",
            "d05f5774d48e41d38492495724a1c166",
            "8e5f99229941409caa469e864473c754",
            "8d7ade74ef1d4b559f70282a6d85606e",
            "688351303f8a4cdcb047dc895b1f6ad5",
            "2e7f010b3e944caa97002f12fa74ce2e"
          ]
        }
      },
      "source": [
        "fit()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "884c0890d9ba4aefa671ad6ab28412d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=4, style=ProgressStyle(description_width='initial…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9673f67935f84aef914587f6cbb93c15",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Iteration', max=17952, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/21/2020 19:17:30 - INFO - __main__ -   Loss after epoc 0.08444994770397801\n",
            "04/21/2020 19:17:30 - INFO - __main__ -   Eval after epoc 1\n",
            "04/21/2020 19:17:50 - INFO - __main__ -   ***** Running evaluation *****\n",
            "04/21/2020 19:17:50 - INFO - __main__ -     Num examples = 15957\n",
            "04/21/2020 19:17:50 - INFO - __main__ -     Batch size = 8\n",
            "04/21/2020 19:22:25 - INFO - __main__ -   ***** Eval results *****\n",
            "04/21/2020 19:22:25 - INFO - __main__ -     eval_accuracy = 0.9824214997936731\n",
            "04/21/2020 19:22:25 - INFO - __main__ -     eval_loss = 0.04673413423915279\n",
            "04/21/2020 19:22:25 - INFO - __main__ -     roc_auc = {0: 0.9855433084706119, 1: 0.9867147440866197, 2: 0.9902604585436752, 3: 0.965726338316038, 4: 0.9857388917840075, 5: 0.987455043500145, 'micro': 0.989987676499644}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef51a39f2da14f28b8ba9f81c6498d61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Iteration', max=17952, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/21/2020 20:48:57 - INFO - __main__ -   Loss after epoc 0.03383085845766176\n",
            "04/21/2020 20:48:57 - INFO - __main__ -   Eval after epoc 2\n",
            "04/21/2020 20:49:16 - INFO - __main__ -   ***** Running evaluation *****\n",
            "04/21/2020 20:49:16 - INFO - __main__ -     Num examples = 15957\n",
            "04/21/2020 20:49:16 - INFO - __main__ -     Batch size = 8\n",
            "04/21/2020 20:53:52 - INFO - __main__ -   ***** Eval results *****\n",
            "04/21/2020 20:53:52 - INFO - __main__ -     eval_accuracy = 0.9849386803300157\n",
            "04/21/2020 20:53:52 - INFO - __main__ -     eval_loss = 0.03761622902275213\n",
            "04/21/2020 20:53:52 - INFO - __main__ -     roc_auc = {0: 0.9881321117807181, 1: 0.9915247206819775, 2: 0.9923303341674494, 3: 0.9824557510669301, 4: 0.9882265527365017, 5: 0.9913538636771535, 'micro': 0.9923540708709482}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "540e0fe269f44260a03d4bff28ae1c82",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Iteration', max=17952, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/21/2020 22:20:33 - INFO - __main__ -   Loss after epoc 0.021238810459550197\n",
            "04/21/2020 22:20:33 - INFO - __main__ -   Eval after epoc 3\n",
            "04/21/2020 22:20:52 - INFO - __main__ -   ***** Running evaluation *****\n",
            "04/21/2020 22:20:52 - INFO - __main__ -     Num examples = 15957\n",
            "04/21/2020 22:20:52 - INFO - __main__ -     Batch size = 8\n",
            "04/21/2020 22:25:27 - INFO - __main__ -   ***** Eval results *****\n",
            "04/21/2020 22:25:27 - INFO - __main__ -     eval_accuracy = 0.9849177902486081\n",
            "04/21/2020 22:25:27 - INFO - __main__ -     eval_loss = 0.04184425362777289\n",
            "04/21/2020 22:25:27 - INFO - __main__ -     roc_auc = {0: 0.9879800430945062, 1: 0.9914287725425754, 2: 0.9934801576495649, 3: 0.9785701782284647, 4: 0.9889904598410122, 5: 0.991905323391016, 'micro': 0.9923777981183979}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "696d052fb7024fefaabbd575164579b2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Iteration', max=17952, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "04/21/2020 23:52:07 - INFO - __main__ -   Loss after epoc 0.012599890498896132\n",
            "04/21/2020 23:52:07 - INFO - __main__ -   Eval after epoc 4\n",
            "04/21/2020 23:52:27 - INFO - __main__ -   ***** Running evaluation *****\n",
            "04/21/2020 23:52:27 - INFO - __main__ -     Num examples = 15957\n",
            "04/21/2020 23:52:27 - INFO - __main__ -     Batch size = 8\n",
            "04/21/2020 23:57:03 - INFO - __main__ -   ***** Eval results *****\n",
            "04/21/2020 23:57:03 - INFO - __main__ -     eval_accuracy = 0.9850117928507992\n",
            "04/21/2020 23:57:03 - INFO - __main__ -     eval_loss = 0.04897612362971601\n",
            "04/21/2020 23:57:03 - INFO - __main__ -     roc_auc = {0: 0.9868300797606543, 1: 0.9913701142914126, 2: 0.9928034117660328, 3: 0.9816594058722445, 4: 0.9857044216906758, 5: 0.9895435718346463, 'micro': 0.9904207150809999}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xLK0oOkRLQes",
        "colab": {}
      },
      "source": [
        "# Save a trained model\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
        "output_model_file = os.path.join(PYTORCH_PRETRAINED_BERT_CACHE, \"finetuned_pytorch_model.bin\")\n",
        "torch.save(model_to_save.state_dict(), output_model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ENhDbABeLWes",
        "colab": {}
      },
      "source": [
        "# Load a trained model that you have fine-tuned\n",
        "model_state_dict = torch.load(output_model_file)\n",
        "model = BertForMultiLabelSequenceClassification.from_pretrained(args['bert_model'], num_labels = num_labels, state_dict=model_state_dict)\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}